{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分三个模型训练："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 模型 1（简单卷积神经网络 CNN）：\n",
    "\n",
    "- 仅包含两个卷积层 + 池化层 + 全连接层\n",
    "\n",
    "- 适合作为Baseline Model，观察基本的分类能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "TRAIN_PATH = \"./train\"\n",
    "VAL_PATH = \"./val\"\n",
    "TEST_PATH = \"./test1\"\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatDogDataset(Dataset):\n",
    "    def __init__(self,train_dir,transform=None):\n",
    "        self.train_dir = train_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(train_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        image_path = os.path.join(self.train_dir,self.images[index])\n",
    "        label = self.images[index].split(\".\")[0]\n",
    "        label = 0 if label=='cat' else 1\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform  is not None:\n",
    "            image = self.transform(image)\n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据增强\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载\n",
    "def load_data():\n",
    "    train_dataset = CatDogDataset(TRAIN_PATH, transform=transform)\n",
    "    val_dataset = CatDogDataset(VAL_PATH, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "train_loader, val_loader = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 32 * 32, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def train_and_evaluate(model, train_loader, val_loader, epochs=10, lr=0.001):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = correct / total\n",
    "        accuracy *= 100\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f168e3cc0664728b03f3aa58b9e25e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5819, Accuracy: 74.80%\n",
      "Epoch 2, Loss: 0.4703, Accuracy: 77.38%\n",
      "Epoch 3, Loss: 0.4130, Accuracy: 78.54%\n",
      "Epoch 4, Loss: 0.3580, Accuracy: 79.54%\n",
      "Epoch 5, Loss: 0.2937, Accuracy: 79.94%\n",
      "Epoch 6, Loss: 0.2356, Accuracy: 78.80%\n",
      "Epoch 7, Loss: 0.1848, Accuracy: 79.64%\n",
      "Epoch 8, Loss: 0.1348, Accuracy: 80.10%\n",
      "Epoch 9, Loss: 0.0967, Accuracy: 80.20%\n",
      "Epoch 10, Loss: 0.0745, Accuracy: 80.48%\n"
     ]
    }
   ],
   "source": [
    "# 训练模型 1\n",
    "model1 = SimpleCNN()\n",
    "train_and_evaluate(model1, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to path:  basecnnmodel\\NAIVECNNCLASSIFIER.pth\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "MODLE_PATH = Path(\"basecnnmodel\")\n",
    "MODLE_PATH.mkdir(parents=True,exist_ok=True)\n",
    "MODLE_NAME = \"NAIVECNNCLASSIFIER.pth\"\n",
    "MODLE_SAVE_PATH = MODLE_PATH / MODLE_NAME\n",
    "print(\"saving to path: \",MODLE_SAVE_PATH)\n",
    "torch.save(obj=model1.state_dict(),f=MODLE_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 模型 2（改进版 CNN）：\n",
    "\n",
    "- 增加卷积层、批量归一化（BatchNorm）、Dropout 以提高泛化能力\n",
    "\n",
    "- 适当增加通道数，提高表达能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImprovedCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 256)\n",
    "        self.fc2 = nn.Linear(256, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d22743a188340a18d076ff330685e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8812, Accuracy: 69.58%\n",
      "Epoch 2, Loss: 0.5908, Accuracy: 71.08%\n",
      "Epoch 3, Loss: 0.5575, Accuracy: 75.56%\n",
      "Epoch 4, Loss: 0.5145, Accuracy: 78.44%\n",
      "Epoch 5, Loss: 0.4865, Accuracy: 81.14%\n",
      "Epoch 6, Loss: 0.4633, Accuracy: 81.24%\n",
      "Epoch 7, Loss: 0.4272, Accuracy: 83.14%\n",
      "Epoch 8, Loss: 0.4054, Accuracy: 83.06%\n",
      "Epoch 9, Loss: 0.3808, Accuracy: 85.90%\n",
      "Epoch 10, Loss: 0.3668, Accuracy: 83.46%\n"
     ]
    }
   ],
   "source": [
    "model2 = ImprovedCNN()\n",
    "train_and_evaluate(model2, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to path:  improvedcnnmodel\\IMPROVEDCNNCLASSIFIER.pth\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "MODLE_PATH = Path(\"improvedcnnmodel\")\n",
    "MODLE_PATH.mkdir(parents=True,exist_ok=True)\n",
    "MODLE_NAME = \"IMPROVEDCNNCLASSIFIER.pth\"\n",
    "MODLE_SAVE_PATH = MODLE_PATH / MODLE_NAME\n",
    "print(\"saving to path: \",MODLE_SAVE_PATH)\n",
    "torch.save(obj=model2.state_dict(),f=MODLE_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 模型 3（ResNet 变种）：\n",
    "\n",
    "- 采用 ResNet-like 结构，引入残差连接（Residual Connection）\n",
    "\n",
    "- 进一步提升分类能力，避免梯度消失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 数据增强\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet 变种\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1) if in_channels != out_channels else nn.Identity()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = self.shortcut(x)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += identity\n",
    "        return self.relu(x)\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.res1 = ResBlock(64, 128)\n",
    "        self.res2 = ResBlock(128, 256)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(256, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.res1(x)\n",
    "        x = self.res2(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, val_loader, epochs=20, lr=0.0005):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)  # 每5轮学习率减半\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = correct / total * 100\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2f6ef2bfb44659a6d6bd8cbe22eeee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6469, Accuracy: 69.30%\n",
      "Epoch 2, Loss: 0.5868, Accuracy: 67.80%\n",
      "Epoch 3, Loss: 0.5603, Accuracy: 70.08%\n",
      "Epoch 4, Loss: 0.5451, Accuracy: 74.46%\n",
      "Epoch 5, Loss: 0.5235, Accuracy: 76.30%\n",
      "Epoch 6, Loss: 0.4902, Accuracy: 79.26%\n",
      "Epoch 7, Loss: 0.4686, Accuracy: 79.24%\n",
      "Epoch 8, Loss: 0.4491, Accuracy: 80.44%\n",
      "Epoch 9, Loss: 0.4328, Accuracy: 71.42%\n",
      "Epoch 10, Loss: 0.4135, Accuracy: 82.24%\n",
      "Epoch 11, Loss: 0.3761, Accuracy: 84.40%\n",
      "Epoch 12, Loss: 0.3654, Accuracy: 83.66%\n",
      "Epoch 13, Loss: 0.3501, Accuracy: 86.50%\n",
      "Epoch 14, Loss: 0.3416, Accuracy: 86.60%\n",
      "Epoch 15, Loss: 0.3313, Accuracy: 86.98%\n",
      "Epoch 16, Loss: 0.3114, Accuracy: 88.36%\n",
      "Epoch 17, Loss: 0.3035, Accuracy: 86.84%\n",
      "Epoch 18, Loss: 0.2965, Accuracy: 88.74%\n",
      "Epoch 19, Loss: 0.2987, Accuracy: 88.36%\n",
      "Epoch 20, Loss: 0.2901, Accuracy: 87.02%\n"
     ]
    }
   ],
   "source": [
    "model3 = ResNet()\n",
    "train_and_evaluate(model3, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to path:  resnetmodel\\RESNETPLUS.pth\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "MODLE_PATH = Path(\"resnetmodel\")\n",
    "MODLE_PATH.mkdir(parents=True,exist_ok=True)\n",
    "MODLE_NAME = \"RESNETPLUS.pth\"\n",
    "MODLE_SAVE_PATH = MODLE_PATH / MODLE_NAME\n",
    "print(\"saving to path: \",MODLE_SAVE_PATH)\n",
    "torch.save(obj=model3.state_dict(),f=MODLE_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3c5cb1521e414ba0633add91b6636b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Image Name Label\n",
      "0      1.jpg   dog\n",
      "1     10.jpg   cat\n",
      "2    100.jpg   cat\n",
      "3   1000.jpg   dog\n",
      "4  10000.jpg   dog\n"
     ]
    }
   ],
   "source": [
    "def predict_and_save_results(model, test_path, output_file):\n",
    "    model.eval()\n",
    "    test_images = os.listdir(test_path)\n",
    "    results = []\n",
    "    \n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    \n",
    "    for img_name in tqdm(test_images):\n",
    "        img_path = os.path.join(test_path, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = transform_test(image)\n",
    "        image = image.unsqueeze(0).to(device)  # 增加 batch 维度\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            label = \"cat\" if predicted.item() == 0 else \"dog\"\n",
    "        \n",
    "        results.append([img_name, label])\n",
    "    \n",
    "    df = pd.DataFrame(results, columns=[\"Image Name\", \"Label\"])\n",
    "    print(df.head())\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "predict_and_save_results(model3, TEST_PATH, \"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         filename label\n",
      "1       1.jpg,dog   nan\n",
      "3613    2.jpg,dog   nan\n",
      "4724    3.jpg,dog   nan\n",
      "5835    4.jpg,dog   nan\n",
      "6946    5.jpg,cat   nan\n",
      "8057    6.jpg,dog   nan\n",
      "9168    7.jpg,cat   nan\n",
      "10279   8.jpg,cat   nan\n",
      "11390   9.jpg,cat   nan\n",
      "2      10.jpg,cat   nan\n",
      "1113   11.jpg,cat   nan\n",
      "2224   12.jpg,dog   nan\n",
      "2836   13.jpg,dog   nan\n",
      "2947   14.jpg,cat   nan\n",
      "3058   15.jpg,cat   nan\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(\"submission.csv\", header=None, names=[\"filename\", \"label\"], sep=\"|\")\n",
    "\n",
    "# 去除可能的空格\n",
    "df[\"filename\"] = df[\"filename\"].astype(str).str.strip()\n",
    "df[\"label\"] = df[\"label\"].astype(str).str.strip()\n",
    "\n",
    "# 提取图片编号\n",
    "df[\"num\"] = df[\"filename\"].str.extract(r\"(\\d+)\")[0]\n",
    "\n",
    "# 删除 NaN 值（即无法提取数字的行）\n",
    "df = df.dropna(subset=[\"num\"])\n",
    "\n",
    "# 转换为整数类型\n",
    "df[\"num\"] = df[\"num\"].astype(int)\n",
    "\n",
    "# 按编号排序\n",
    "df = df.sort_values(by=\"num\")\n",
    "\n",
    "# 删除辅助列\n",
    "df = df.drop(columns=[\"num\"])\n",
    "\n",
    "# 重新保存排序后的 CSV，确保没有额外的 `NaN`\n",
    "df.to_csv(\"submission_sorted.csv\", index=False, header=False, sep=\"|\", na_rep=\"\")\n",
    "\n",
    "# 打印前几行检查\n",
    "print(df.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (res1): ResBlock(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (shortcut): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (res2): ResBlock(\n",
       "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet()\n",
    "MODLE_PATH = Path(\"resnetmodel\")\n",
    "MODLE_PATH.mkdir(parents=True,exist_ok=True)\n",
    "MODLE_NAME = \"RESNETPLUS.pth\"\n",
    "MODLE_SAVE_PATH = MODLE_PATH / MODLE_NAME\n",
    "model.load_state_dict(torch.load(MODLE_SAVE_PATH))\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
